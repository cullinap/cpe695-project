{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost --quiet\n",
    "!pip install keras --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_vals(dframe) -> list:\n",
    "    return sorted([(c, dframe[c].dtype, dframe[c].isnull().sum()) \n",
    "                        for c in dframe.columns if dframe[c].isnull().sum() > 0], \n",
    "                      key=lambda x: x[1], reverse=True\n",
    "                )\n",
    "\n",
    "def metric_report(yTest, yPred):\n",
    "    print(f'accuracy: {accuracy_score(yTest, yPred)}')\n",
    "    print('')\n",
    "    print(\"Classification report: \\n\\n\", metrics.classification_report(yTest, yPred))\n",
    "    print('')\n",
    "    confusion_matrix = metrics.confusion_matrix(yTest, yPred)\n",
    "    print(\"Confusion matrix: \\n\\n\", confusion_matrix)\n",
    "\n",
    "    \n",
    "def clean_txt(txtCol: pd.Series) -> pd.Series:\n",
    "    sw = set(stopwords.words('English'))\n",
    "\n",
    "    text = txtCol.apply(gensim.utils.simple_preprocess, min_len=3)\n",
    "    text = text.apply(lambda s: [w for w in s if w not in sw]) \n",
    "    text = text.apply(lambda s: [SnowballStemmer(\"english\", ignore_stopwords=True).stem(w) for w in s])\n",
    "    text = text.apply(lambda s: ['_'.join(x) for x in nltk.bigrams(s)] + s)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, exclude) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get all txt data, put in list of dicts and return a dataframe\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file not in (exclude):\n",
    "            full_filename = os.path.join(path, file)\n",
    "            for news in os.listdir(full_filename):\n",
    "                with open(os.path.join(full_filename, news), 'rb') as txt_file:\n",
    "                    data.append({'NewsText': txt_file.read(), 'NewsType': file})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "import pickle\n",
    "\n",
    "def picklefy(txtCol: pd.DataFrame) -> pd.DataFrame:\n",
    "    if [f for f in os.listdir('.') if f.endswith('p')]:\n",
    "        return pickle.load(open('tfidf.p','rb'))\n",
    "    return pickle.dump(clean_txt(txtCol['NewsText']), open('tfidf.p', 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsText</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Musicians to tackle US red tape\\n\\nMusicians...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'U2\\'s desire to be number one\\n\\nU2, who hav...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            NewsText       NewsType\n",
       "0  b'Musicians to tackle US red tape\\n\\nMusicians...  entertainment\n",
       "1  b'U2\\'s desire to be number one\\n\\nU2, who hav...  entertainment"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preemtively drop duplicates\n",
    "df = get_data('bbc/', 'README.TXT').drop_duplicates(); df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsText</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2127</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2127</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>b'Musicians to tackle US red tape\\n\\nMusicians...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 NewsText NewsType\n",
       "count                                                2127     2127\n",
       "unique                                               2127        5\n",
       "top     b'Musicians to tackle US red tape\\n\\nMusicians...    sport\n",
       "freq                                                    1      505"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, \n",
    "                        min_df=5, norm='l2', \n",
    "                        encoding='latin-1', \n",
    "                        #ngram_range=(1, 2),\n",
    "                        stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTxtCol = picklefy(df).apply(lambda x: ' '.join(i for i in x))\n",
    "\n",
    "features = tfidf.fit_transform(cleanTxtCol).toarray() \n",
    "labels = df.NewsType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "\n",
    "X = features\n",
    "y = LE.fit_transform(labels)\n",
    "\n",
    "# train/test/split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                            X,y, test_size=0.2\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8544600938967136\n",
      "\n",
      "Classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84        98\n",
      "           1       0.75      0.82      0.78        55\n",
      "           2       0.89      0.83      0.86        94\n",
      "           3       0.93      0.91      0.92       101\n",
      "           4       0.85      0.82      0.84        78\n",
      "\n",
      "    accuracy                           0.85       426\n",
      "   macro avg       0.85      0.85      0.85       426\n",
      "weighted avg       0.86      0.85      0.86       426\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[85  5  2  0  6]\n",
      " [ 1 45  4  3  2]\n",
      " [12  0 78  2  2]\n",
      " [ 1  5  2 92  1]\n",
      " [ 5  5  2  2 64]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metric_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "xg_clf = XGBClassifier(random_state=42, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:41:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy: 0.9389671361502347\n",
      "\n",
      "Classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        98\n",
      "           1       0.93      0.93      0.93        55\n",
      "           2       0.96      0.95      0.95        94\n",
      "           3       0.98      0.99      0.99       101\n",
      "           4       0.93      0.88      0.91        78\n",
      "\n",
      "    accuracy                           0.94       426\n",
      "   macro avg       0.94      0.94      0.94       426\n",
      "weighted avg       0.94      0.94      0.94       426\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[ 91   3   3   0   1]\n",
      " [  1  51   0   1   2]\n",
      " [  3   0  89   0   2]\n",
      " [  1   0   0 100   0]\n",
      " [  6   1   1   1  69]]\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "metric_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "params = {\"objective\":\"binary:logistic\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 5, \n",
    "          'alpha': 10}\n",
    "\n",
    "xgb_cv = cv(dtrain=data_dmatrix, \n",
    "            params=params, \n",
    "            nfold=5,\n",
    "            num_boost_round=50,\n",
    "            early_stopping_rounds=10, \n",
    "            metrics=\"auc\", \n",
    "            as_pandas=True, \n",
    "            seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
